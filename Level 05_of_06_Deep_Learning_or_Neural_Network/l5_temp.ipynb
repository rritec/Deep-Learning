{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic_all_numeric_train.csv\")\n",
    "X_train=df.drop(labels=[\"survived\"],axis=1).values\n",
    "y_train=to_categorical(df.survived)\n",
    "n_features=X_train.shape[1]\n",
    "## importing test data\n",
    "df = pd.read_csv(\"titanic_all_numeric_test.csv\")\n",
    "X_test=df.drop(labels=[\"survived\"],axis=1).values\n",
    "y_test=to_categorical(df.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_get_model(arg1_n_features):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(100,\n",
    "               activation=\"relu\",\n",
    "               input_shape =(n_features,),\n",
    "                name = \"input_and_firsthidden_layer\"))\n",
    "    model.add(Dense(100,\n",
    "               activation=\"relu\",\n",
    "               name = \"second_hidden_layer\"))\n",
    "    model.add(Dense(2,\n",
    "               activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "# SVG(data=model_to_dot(model, \n",
    "#                       show_shapes=True, \n",
    "#                       show_layer_names=True, rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_to_test = [.00000001, 0.01, 1]\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model training with learning rate :1e-08\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 2.2097 - acc: 0.5196\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 111us/step - loss: 2.2096 - acc: 0.5196\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 100us/step - loss: 2.2095 - acc: 0.5196\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 88us/step - loss: 2.2094 - acc: 0.5196\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 129us/step - loss: 2.2094 - acc: 0.5196\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 131us/step - loss: 2.2093 - acc: 0.5196\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 160us/step - loss: 2.2093 - acc: 0.5196\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 95us/step - loss: 2.2092 - acc: 0.5196\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 177us/step - loss: 2.2091 - acc: 0.5196\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 107us/step - loss: 2.2090 - acc: 0.5196\n",
      "The model training with learning rate :0.01\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.4215 - acc: 0.6027\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.8226 - acc: 0.6431\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.7022 - acc: 0.6768\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 112us/step - loss: 0.6208 - acc: 0.6824\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.6101 - acc: 0.6880\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 98us/step - loss: 0.6301 - acc: 0.6689\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 146us/step - loss: 0.5879 - acc: 0.6958\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 120us/step - loss: 0.6002 - acc: 0.6880\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.5918 - acc: 0.6790\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.5878 - acc: 0.7093\n",
      "The model training with learning rate :1\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 9.5610 - acc: 0.3951\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 122us/step - loss: 9.8772 - acc: 0.3838\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 142us/step - loss: 9.8772 - acc: 0.3838\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 119us/step - loss: 9.8772 - acc: 0.3838\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 167us/step - loss: 9.8772 - acc: 0.3838\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 171us/step - loss: 9.8772 - acc: 0.3838\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 162us/step - loss: 9.8772 - acc: 0.3838\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 144us/step - loss: 9.8772 - acc: 0.3838\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - ETA: 0s - loss: 9.9950 - acc: 0.3765 - 0s 178us/step - loss: 9.8772 - acc: 0.3838\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 129us/step - loss: 9.8772 - acc: 0.3838\n"
     ]
    }
   ],
   "source": [
    "for lr in lr_to_test:\n",
    "    print(f\"The model training with learning rate :{lr}\")\n",
    "    model=fun_get_model(n_features)\n",
    "    my_optimizer = SGD(lr)\n",
    "    model.compile(optimizer=my_optimizer,\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0222 08:17:31.020684 15248 deprecation_wrapper.py:119] From C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "891/891 [==============================] - 1s 655us/step - loss: 3.0606 - acc: 0.5937\n",
      "Epoch 2/100\n",
      "891/891 [==============================] - 0s 144us/step - loss: 1.6636 - acc: 0.6173\n",
      "Epoch 3/100\n",
      "891/891 [==============================] - 0s 110us/step - loss: 1.1850 - acc: 0.6207\n",
      "Epoch 4/100\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.8086 - acc: 0.6521\n",
      "Epoch 5/100\n",
      "891/891 [==============================] - 0s 124us/step - loss: 0.6757 - acc: 0.6465\n",
      "Epoch 6/100\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.6339 - acc: 0.6914\n",
      "Epoch 7/100\n",
      "891/891 [==============================] - 0s 128us/step - loss: 0.5981 - acc: 0.6981\n",
      "Epoch 8/100\n",
      "891/891 [==============================] - 0s 123us/step - loss: 0.6028 - acc: 0.6992\n",
      "Epoch 9/100\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.5930 - acc: 0.7048 0s - loss: 0.5919 - acc: 0.707\n",
      "Epoch 10/100\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.5786 - acc: 0.724 - 0s 139us/step - loss: 0.5893 - acc: 0.7104\n",
      "Epoch 11/100\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.5921 - acc: 0.7160\n",
      "Epoch 12/100\n",
      "891/891 [==============================] - 0s 116us/step - loss: 0.5905 - acc: 0.6958\n",
      "Epoch 13/100\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.5899 - acc: 0.6914\n",
      "Epoch 14/100\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.5861 - acc: 0.7116\n",
      "Epoch 15/100\n",
      "891/891 [==============================] - 0s 115us/step - loss: 0.5836 - acc: 0.7015\n",
      "Epoch 16/100\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.5783 - acc: 0.7127\n",
      "Epoch 17/100\n",
      "891/891 [==============================] - 0s 133us/step - loss: 0.5919 - acc: 0.7138\n",
      "Epoch 18/100\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.5762 - acc: 0.7104\n",
      "Epoch 19/100\n",
      "891/891 [==============================] - 0s 127us/step - loss: 0.5791 - acc: 0.7015\n",
      "Epoch 20/100\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.5766 - acc: 0.7015\n",
      "Epoch 21/100\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.5781 - acc: 0.7093\n",
      "Epoch 22/100\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.5810 - acc: 0.7059\n",
      "Epoch 23/100\n",
      "891/891 [==============================] - 0s 260us/step - loss: 0.5720 - acc: 0.7183\n",
      "Epoch 24/100\n",
      "891/891 [==============================] - 0s 108us/step - loss: 0.5711 - acc: 0.7015\n",
      "Epoch 25/100\n",
      "891/891 [==============================] - 0s 137us/step - loss: 0.5779 - acc: 0.7194\n",
      "Epoch 26/100\n",
      "891/891 [==============================] - 0s 112us/step - loss: 0.5776 - acc: 0.7082\n",
      "Epoch 27/100\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.5788 - acc: 0.7127\n",
      "Epoch 28/100\n",
      "891/891 [==============================] - 0s 85us/step - loss: 0.5673 - acc: 0.7172\n",
      "Epoch 29/100\n",
      "891/891 [==============================] - 0s 139us/step - loss: 0.5735 - acc: 0.7194\n",
      "Epoch 30/100\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.5588 - acc: 0.7172\n",
      "Epoch 31/100\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.5703 - acc: 0.7149 0s - loss: 0.5796 - acc: 0.701\n",
      "Epoch 32/100\n",
      "891/891 [==============================] - 0s 129us/step - loss: 0.5721 - acc: 0.7127\n",
      "Epoch 33/100\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.5620 - acc: 0.730 - 0s 136us/step - loss: 0.5669 - acc: 0.7205\n",
      "Epoch 34/100\n",
      "891/891 [==============================] - 0s 122us/step - loss: 0.5724 - acc: 0.7082\n",
      "Epoch 35/100\n",
      "891/891 [==============================] - 0s 94us/step - loss: 0.5584 - acc: 0.7160\n",
      "Epoch 36/100\n",
      "891/891 [==============================] - 0s 98us/step - loss: 0.5733 - acc: 0.7160\n",
      "Epoch 37/100\n",
      "891/891 [==============================] - 0s 107us/step - loss: 0.5644 - acc: 0.7104\n",
      "Epoch 38/100\n",
      "891/891 [==============================] - 0s 128us/step - loss: 0.5622 - acc: 0.7059\n",
      "Epoch 39/100\n",
      "891/891 [==============================] - 0s 104us/step - loss: 0.5526 - acc: 0.7205\n",
      "Epoch 40/100\n",
      "891/891 [==============================] - 0s 98us/step - loss: 0.5635 - acc: 0.7205\n",
      "Epoch 41/100\n",
      "891/891 [==============================] - 0s 89us/step - loss: 0.5731 - acc: 0.7138: 0s - loss: 0.5756 - acc: 0.712\n",
      "Epoch 42/100\n",
      "891/891 [==============================] - 0s 90us/step - loss: 0.5676 - acc: 0.7149\n",
      "Epoch 43/100\n",
      "891/891 [==============================] - 0s 143us/step - loss: 0.5596 - acc: 0.7250\n",
      "Epoch 44/100\n",
      "891/891 [==============================] - 0s 136us/step - loss: 0.5668 - acc: 0.7104\n",
      "Epoch 45/100\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.5604 - acc: 0.7295\n",
      "Epoch 46/100\n",
      "891/891 [==============================] - 0s 110us/step - loss: 0.5588 - acc: 0.7318\n",
      "Epoch 47/100\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.5666 - acc: 0.7172\n",
      "Epoch 48/100\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.5590 - acc: 0.7082\n",
      "Epoch 49/100\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.5563 - acc: 0.7149\n",
      "Epoch 50/100\n",
      "891/891 [==============================] - 0s 103us/step - loss: 0.5510 - acc: 0.7250\n",
      "Epoch 51/100\n",
      "891/891 [==============================] - 0s 76us/step - loss: 0.5589 - acc: 0.7149\n",
      "Epoch 52/100\n",
      "891/891 [==============================] - 0s 98us/step - loss: 0.5593 - acc: 0.7217\n",
      "Epoch 53/100\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.5538 - acc: 0.7194\n",
      "Epoch 54/100\n",
      "891/891 [==============================] - 0s 100us/step - loss: 0.5714 - acc: 0.7093\n",
      "Epoch 55/100\n",
      "891/891 [==============================] - 0s 142us/step - loss: 0.5542 - acc: 0.7295\n",
      "Epoch 56/100\n",
      "891/891 [==============================] - 0s 112us/step - loss: 0.5486 - acc: 0.7295\n",
      "Epoch 57/100\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.5499 - acc: 0.7363\n",
      "Epoch 58/100\n",
      "891/891 [==============================] - 0s 117us/step - loss: 0.5641 - acc: 0.7172\n",
      "Epoch 59/100\n",
      "891/891 [==============================] - 0s 95us/step - loss: 0.5515 - acc: 0.7183\n",
      "Epoch 60/100\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.5426 - acc: 0.7284\n",
      "Epoch 61/100\n",
      "891/891 [==============================] - 0s 142us/step - loss: 0.5498 - acc: 0.7374\n",
      "Epoch 62/100\n",
      "891/891 [==============================] - 0s 118us/step - loss: 0.5485 - acc: 0.7250\n",
      "Epoch 63/100\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.5581 - acc: 0.7127\n",
      "Epoch 64/100\n",
      "891/891 [==============================] - 0s 269us/step - loss: 0.5337 - acc: 0.7452 0s - loss: 0.5302 - acc: 0.74\n",
      "Epoch 65/100\n",
      "891/891 [==============================] - 0s 100us/step - loss: 0.5366 - acc: 0.7183\n",
      "Epoch 66/100\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.5603 - acc: 0.7273\n",
      "Epoch 67/100\n",
      "891/891 [==============================] - 0s 109us/step - loss: 0.5412 - acc: 0.7329\n",
      "Epoch 68/100\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.5291 - acc: 0.7396\n",
      "Epoch 69/100\n",
      "891/891 [==============================] - 0s 141us/step - loss: 0.5519 - acc: 0.7127\n",
      "Epoch 70/100\n",
      "891/891 [==============================] - 0s 97us/step - loss: 0.5433 - acc: 0.7284\n",
      "Epoch 71/100\n",
      "891/891 [==============================] - 0s 81us/step - loss: 0.5485 - acc: 0.7250\n",
      "Epoch 72/100\n",
      "891/891 [==============================] - 0s 139us/step - loss: 0.5332 - acc: 0.7520\n",
      "Epoch 73/100\n",
      "891/891 [==============================] - 0s 104us/step - loss: 0.5264 - acc: 0.7396\n",
      "Epoch 74/100\n",
      "891/891 [==============================] - 0s 87us/step - loss: 0.5551 - acc: 0.7183\n",
      "Epoch 75/100\n",
      "891/891 [==============================] - 0s 107us/step - loss: 0.5384 - acc: 0.7284\n",
      "Epoch 76/100\n",
      "891/891 [==============================] - 0s 109us/step - loss: 0.5318 - acc: 0.7520\n",
      "Epoch 77/100\n",
      "891/891 [==============================] - 0s 95us/step - loss: 0.5451 - acc: 0.7385\n",
      "Epoch 78/100\n",
      "891/891 [==============================] - 0s 80us/step - loss: 0.5353 - acc: 0.7396\n",
      "Epoch 79/100\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.5304 - acc: 0.752 - 0s 77us/step - loss: 0.5313 - acc: 0.7486\n",
      "Epoch 80/100\n",
      "891/891 [==============================] - 0s 106us/step - loss: 0.5423 - acc: 0.7217\n",
      "Epoch 81/100\n",
      "891/891 [==============================] - 0s 83us/step - loss: 0.5305 - acc: 0.7407\n",
      "Epoch 82/100\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.5306 - acc: 0.7340\n",
      "Epoch 83/100\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.5353 - acc: 0.7407 0s - loss: 0.5376 - acc: 0.742\n",
      "Epoch 84/100\n",
      "891/891 [==============================] - 0s 114us/step - loss: 0.5291 - acc: 0.7396\n",
      "Epoch 85/100\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.5440 - acc: 0.7351\n",
      "Epoch 86/100\n",
      "891/891 [==============================] - 0s 103us/step - loss: 0.5267 - acc: 0.7531\n",
      "Epoch 87/100\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.5373 - acc: 0.7452\n",
      "Epoch 88/100\n",
      "891/891 [==============================] - 0s 139us/step - loss: 0.5240 - acc: 0.7553\n",
      "Epoch 89/100\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.5248 - acc: 0.7531 0s - loss: 0.5219 - acc: 0.75\n",
      "Epoch 90/100\n",
      "891/891 [==============================] - 0s 129us/step - loss: 0.5374 - acc: 0.7486\n",
      "Epoch 91/100\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.5291 - acc: 0.7385\n",
      "Epoch 92/100\n",
      "891/891 [==============================] - 0s 132us/step - loss: 0.5299 - acc: 0.7430\n",
      "Epoch 93/100\n",
      "891/891 [==============================] - 0s 115us/step - loss: 0.5582 - acc: 0.7374\n",
      "Epoch 94/100\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.5232 - acc: 0.7565\n",
      "Epoch 95/100\n",
      "891/891 [==============================] - 0s 98us/step - loss: 0.5291 - acc: 0.7520\n",
      "Epoch 96/100\n",
      "891/891 [==============================] - 0s 95us/step - loss: 0.5347 - acc: 0.7363\n",
      "Epoch 97/100\n",
      "891/891 [==============================] - 0s 90us/step - loss: 0.5442 - acc: 0.7284\n",
      "Epoch 98/100\n",
      "891/891 [==============================] - 0s 103us/step - loss: 0.5211 - acc: 0.7531\n",
      "Epoch 99/100\n",
      "891/891 [==============================] - 0s 107us/step - loss: 0.5181 - acc: 0.7576\n",
      "Epoch 100/100\n",
      "891/891 [==============================] - 0s 85us/step - loss: 0.5365 - acc: 0.7542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1438e1358>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/ramreddymyla/Desktop/rritec/b20200222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_20200222.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model('model_20200222.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_calculation=my_model.predict(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8156826 , 0.18431737],\n",
       "       [0.1738516 , 0.82614833],\n",
       "       [0.48516807, 0.5148319 ],\n",
       "       [0.1720456 , 0.8279544 ],\n",
       "       [0.77975225, 0.22024778],\n",
       "       [0.7436762 , 0.2563238 ],\n",
       "       [0.28999946, 0.7100005 ],\n",
       "       [0.6862207 , 0.31377932],\n",
       "       [0.41794658, 0.58205336],\n",
       "       [0.28321847, 0.7167815 ],\n",
       "       [0.43559104, 0.56440896],\n",
       "       [0.25275996, 0.74724007],\n",
       "       [0.74585295, 0.25414705],\n",
       "       [0.6645046 , 0.33549544],\n",
       "       [0.45372304, 0.5462769 ],\n",
       "       [0.31982473, 0.6801753 ],\n",
       "       [0.6192875 , 0.38071254],\n",
       "       [0.7076203 , 0.29237974],\n",
       "       [0.35134533, 0.64865476],\n",
       "       [0.48405468, 0.5159453 ],\n",
       "       [0.44820735, 0.5517927 ],\n",
       "       [0.6219418 , 0.37805817],\n",
       "       [0.3692601 , 0.6307399 ],\n",
       "       [0.354624  , 0.6453759 ],\n",
       "       [0.60653174, 0.39346826],\n",
       "       [0.49075484, 0.50924516],\n",
       "       [0.7610711 , 0.23892884],\n",
       "       [0.28780308, 0.7121969 ],\n",
       "       [0.47689933, 0.5231007 ],\n",
       "       [0.8247751 , 0.17522492],\n",
       "       [0.35175377, 0.6482462 ],\n",
       "       [0.23899977, 0.7610002 ],\n",
       "       [0.48033053, 0.5196695 ],\n",
       "       [0.78044564, 0.2195544 ],\n",
       "       [0.2483719 , 0.75162804],\n",
       "       [0.31500092, 0.68499905],\n",
       "       [0.76098895, 0.2390111 ],\n",
       "       [0.7479294 , 0.25207058],\n",
       "       [0.45862788, 0.54137206],\n",
       "       [0.3889093 , 0.61109066],\n",
       "       [0.56158656, 0.43841344],\n",
       "       [0.31753248, 0.6824675 ],\n",
       "       [0.74770176, 0.25229827],\n",
       "       [0.2958247 , 0.7041753 ],\n",
       "       [0.3762569 , 0.62374306],\n",
       "       [0.8223647 , 0.17763539],\n",
       "       [0.6855836 , 0.31441644],\n",
       "       [0.48033053, 0.5196695 ],\n",
       "       [0.6389603 , 0.3610397 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18431737, 0.82614833, 0.5148319 , 0.8279544 , 0.22024778,\n",
       "       0.2563238 , 0.7100005 , 0.31377932, 0.58205336, 0.7167815 ,\n",
       "       0.56440896, 0.74724007, 0.25414705, 0.33549544, 0.5462769 ,\n",
       "       0.6801753 , 0.38071254, 0.29237974, 0.64865476, 0.5159453 ,\n",
       "       0.5517927 , 0.37805817, 0.6307399 , 0.6453759 , 0.39346826,\n",
       "       0.50924516, 0.23892884, 0.7121969 , 0.5231007 , 0.17522492,\n",
       "       0.6482462 , 0.7610002 , 0.5196695 , 0.2195544 , 0.75162804,\n",
       "       0.68499905, 0.2390111 , 0.25207058, 0.54137206, 0.61109066,\n",
       "       0.43841344, 0.6824675 , 0.25229827, 0.7041753 , 0.62374306,\n",
       "       0.17763539, 0.31441644, 0.5196695 , 0.3610397 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.round(label_calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    1\n",
       "16    0\n",
       "17    1\n",
       "18    0\n",
       "19    1\n",
       "20    0\n",
       "21    1\n",
       "22    1\n",
       "23    1\n",
       "24    0\n",
       "25    1\n",
       "26    0\n",
       "27    0\n",
       "28    1\n",
       "29    0\n",
       "30    0\n",
       "31    1\n",
       "32    1\n",
       "33    0\n",
       "34    0\n",
       "35    0\n",
       "36    1\n",
       "37    0\n",
       "38    0\n",
       "39    1\n",
       "40    0\n",
       "41    0\n",
       "42    0\n",
       "43    1\n",
       "44    1\n",
       "45    0\n",
       "46    0\n",
       "47    1\n",
       "48    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
