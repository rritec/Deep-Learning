{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Creating Classification Models using Keras & TensorFlow`\n",
    "----\n",
    "1. Use <code>categorical_crossentropy</code> as loss function for multi-class classification (Example Dataset : iris.csv,MNIST.csv...etc)\n",
    "\n",
    "2. Use <code>binary_crossentropy</code> as loss function for binary classification(Example Dataset : Pima_indians_diabtes.csv,Titanic.csv...etc\n",
    "    - Similar to log loss: **Lower is better**\n",
    "3. Add <code>metrics = ['accuracy']</code> to compile step for easy-to-understand diagnostics\n",
    "4. Output layer should has separate node for each possible outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Scenerio: Predict survival on the Titanic disaster\n",
    "1. Modelling with a dataset \"Titanic\" for a classification problem\n",
    "    - You will use predictors/inputs such as \n",
    "        - age\n",
    "        - fare\n",
    "        - embarked\n",
    "        - .. etc to predict who will survive.\n",
    "    - [Refer more information from kaggle](https://www.kaggle.com/startupsci/titanic-data-science-solutions/notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# define Architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# for Model Vizulization\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Import the train and test data from different csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "df = pd.read_csv(\"titanic_all_numeric_train.csv\")\n",
    "\n",
    "####  Separate X_train and y_train\n",
    "# create X_train and creat 2d numpy array\n",
    "X_train = df.drop(['survived'], axis=1).values\n",
    "\n",
    "# create y_train and creat 2d numpy array\n",
    "y_train = to_categorical(df.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the number of input columns: n_cols\n",
    "n_cols = X_train.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic_all_numeric_test.csv\")\n",
    "\n",
    "# create X_test and creat 2d numpy array\n",
    "X_test = df.drop(['survived'], axis=1).values\n",
    "\n",
    "# create y_test and creat 2d numpy array\n",
    "y_test= to_categorical(df.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Architecture of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0221 10:35:21.360306 14040 deprecation_wrapper.py:119] From C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0221 10:35:21.392578 14040 deprecation_wrapper.py:119] From C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0221 10:35:21.401208 14040 deprecation_wrapper.py:119] From C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer and input layer\n",
    "model.add(Dense(32,activation='relu',\n",
    "                input_shape=(n_cols,),\n",
    "                name=\"Input_1stHiddenlayer\"))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2,activation='softmax',\n",
    "                name =\"output_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"211pt\" viewBox=\"0.00 0.00 319.00 211.00\" width=\"319pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-207 315,-207 315,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2025706799000 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2025706799000</title>\n",
       "<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 311,-129.5 311,-83.5 0,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89\" y=\"-102.8\">Input_1stHiddenlayer: Dense</text>\n",
       "<polyline fill=\"none\" points=\"178,-83.5 178,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"178,-106.5 234,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"234,-83.5 234,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-114.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"234,-106.5 311,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-91.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 2025707098576 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2025707098576</title>\n",
       "<polygon fill=\"none\" points=\"25,-0.5 25,-46.5 286,-46.5 286,-0.5 25,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89\" y=\"-19.8\">output_layer: Dense</text>\n",
       "<polyline fill=\"none\" points=\"153,-0.5 153,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"153,-23.5 209,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"209,-0.5 209,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-31.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"209,-23.5 286,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-8.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 2025706799000&#45;&gt;2025707098576 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2025706799000-&gt;2025707098576</title>\n",
       "<path d=\"M155.5,-83.3664C155.5,-75.1516 155.5,-65.6579 155.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"159,-56.6068 155.5,-46.6068 152,-56.6069 159,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2025707099136 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2025707099136</title>\n",
       "<polygon fill=\"none\" points=\"103.5,-166.5 103.5,-202.5 207.5,-202.5 207.5,-166.5 103.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.5\" y=\"-180.8\">2025707099136</text>\n",
       "</g>\n",
       "<!-- 2025707099136&#45;&gt;2025706799000 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2025707099136-&gt;2025706799000</title>\n",
       "<path d=\"M155.5,-166.254C155.5,-158.363 155.5,-148.749 155.5,-139.602\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"159,-139.591 155.5,-129.591 152,-139.591 159,-139.591\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model,show_shapes=True, show_layer_names=True,).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0221 10:35:22.246993 14040 deprecation_wrapper.py:119] From C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0221 10:35:22.275808 14040 deprecation_wrapper.py:119] From C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0221 10:35:22.287811 14040 deprecation.py:323] From C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit /Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0221 10:35:22.669512 14040 deprecation_wrapper.py:119] From C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "891/891 [==============================] - 1s 635us/step - loss: 3.9344 - acc: 0.5623\n",
      "Epoch 2/100\n",
      "891/891 [==============================] - 0s 45us/step - loss: 1.1448 - acc: 0.6622\n",
      "Epoch 3/100\n",
      "891/891 [==============================] - 0s 44us/step - loss: 0.8139 - acc: 0.6296\n",
      "Epoch 4/100\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.6227 - acc: 0.6723\n",
      "Epoch 5/100\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.6198 - acc: 0.6801\n",
      "Epoch 6/100\n",
      "891/891 [==============================] - 0s 51us/step - loss: 0.6138 - acc: 0.6835\n",
      "Epoch 7/100\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.5987 - acc: 0.6768\n",
      "Epoch 8/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.6108 - acc: 0.6756\n",
      "Epoch 9/100\n",
      "891/891 [==============================] - 0s 71us/step - loss: 0.5806 - acc: 0.7037\n",
      "Epoch 10/100\n",
      "891/891 [==============================] - 0s 83us/step - loss: 0.5778 - acc: 0.6947\n",
      "Epoch 11/100\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.5747 - acc: 0.6914\n",
      "Epoch 12/100\n",
      "891/891 [==============================] - 0s 57us/step - loss: 0.5826 - acc: 0.6947\n",
      "Epoch 13/100\n",
      "891/891 [==============================] - 0s 67us/step - loss: 0.5798 - acc: 0.6958\n",
      "Epoch 14/100\n",
      "891/891 [==============================] - 0s 62us/step - loss: 0.5813 - acc: 0.6947\n",
      "Epoch 15/100\n",
      "891/891 [==============================] - 0s 59us/step - loss: 0.5666 - acc: 0.7026\n",
      "Epoch 16/100\n",
      "891/891 [==============================] - 0s 68us/step - loss: 0.5757 - acc: 0.6936\n",
      "Epoch 17/100\n",
      "891/891 [==============================] - 0s 74us/step - loss: 0.5646 - acc: 0.7116\n",
      "Epoch 18/100\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.5744 - acc: 0.6981\n",
      "Epoch 19/100\n",
      "891/891 [==============================] - 0s 75us/step - loss: 0.5710 - acc: 0.6992\n",
      "Epoch 20/100\n",
      "891/891 [==============================] - 0s 56us/step - loss: 0.5715 - acc: 0.7228\n",
      "Epoch 21/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5645 - acc: 0.7205\n",
      "Epoch 22/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5668 - acc: 0.7003\n",
      "Epoch 23/100\n",
      "891/891 [==============================] - 0s 45us/step - loss: 0.5699 - acc: 0.7172\n",
      "Epoch 24/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5735 - acc: 0.7138\n",
      "Epoch 25/100\n",
      "891/891 [==============================] - 0s 52us/step - loss: 0.5640 - acc: 0.7127\n",
      "Epoch 26/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5563 - acc: 0.7116\n",
      "Epoch 27/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5621 - acc: 0.7183\n",
      "Epoch 28/100\n",
      "891/891 [==============================] - 0s 45us/step - loss: 0.5585 - acc: 0.7026\n",
      "Epoch 29/100\n",
      "891/891 [==============================] - 0s 57us/step - loss: 0.5743 - acc: 0.7082\n",
      "Epoch 30/100\n",
      "891/891 [==============================] - 0s 55us/step - loss: 0.5458 - acc: 0.7183\n",
      "Epoch 31/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5569 - acc: 0.7183\n",
      "Epoch 32/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5613 - acc: 0.7104\n",
      "Epoch 33/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5560 - acc: 0.7284\n",
      "Epoch 34/100\n",
      "891/891 [==============================] - 0s 51us/step - loss: 0.5590 - acc: 0.7194\n",
      "Epoch 35/100\n",
      "891/891 [==============================] - 0s 56us/step - loss: 0.5729 - acc: 0.7015\n",
      "Epoch 36/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5519 - acc: 0.7295\n",
      "Epoch 37/100\n",
      "891/891 [==============================] - 0s 46us/step - loss: 0.5664 - acc: 0.7048\n",
      "Epoch 38/100\n",
      "891/891 [==============================] - 0s 51us/step - loss: 0.5563 - acc: 0.7363\n",
      "Epoch 39/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5501 - acc: 0.7205\n",
      "Epoch 40/100\n",
      "891/891 [==============================] - 0s 78us/step - loss: 0.5697 - acc: 0.7059\n",
      "Epoch 41/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5576 - acc: 0.7026\n",
      "Epoch 42/100\n",
      "891/891 [==============================] - 0s 53us/step - loss: 0.5398 - acc: 0.7340\n",
      "Epoch 43/100\n",
      "891/891 [==============================] - 0s 57us/step - loss: 0.5635 - acc: 0.7160\n",
      "Epoch 44/100\n",
      "891/891 [==============================] - 0s 50us/step - loss: 0.5660 - acc: 0.7273\n",
      "Epoch 45/100\n",
      "891/891 [==============================] - 0s 53us/step - loss: 0.5562 - acc: 0.7172\n",
      "Epoch 46/100\n",
      "891/891 [==============================] - 0s 56us/step - loss: 0.5361 - acc: 0.7205\n",
      "Epoch 47/100\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.5428 - acc: 0.7363\n",
      "Epoch 48/100\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.5643 - acc: 0.7138\n",
      "Epoch 49/100\n",
      "891/891 [==============================] - 0s 51us/step - loss: 0.5571 - acc: 0.7295\n",
      "Epoch 50/100\n",
      "891/891 [==============================] - 0s 50us/step - loss: 0.5546 - acc: 0.7329\n",
      "Epoch 51/100\n",
      "891/891 [==============================] - 0s 55us/step - loss: 0.5549 - acc: 0.7183\n",
      "Epoch 52/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5522 - acc: 0.7228\n",
      "Epoch 53/100\n",
      "891/891 [==============================] - 0s 55us/step - loss: 0.5481 - acc: 0.7138\n",
      "Epoch 54/100\n",
      "891/891 [==============================] - 0s 50us/step - loss: 0.5419 - acc: 0.7396\n",
      "Epoch 55/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5579 - acc: 0.7183\n",
      "Epoch 56/100\n",
      "891/891 [==============================] - 0s 50us/step - loss: 0.5555 - acc: 0.7082\n",
      "Epoch 57/100\n",
      "891/891 [==============================] - 0s 52us/step - loss: 0.5277 - acc: 0.7497\n",
      "Epoch 58/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5414 - acc: 0.7385\n",
      "Epoch 59/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5567 - acc: 0.7306\n",
      "Epoch 60/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5389 - acc: 0.7363\n",
      "Epoch 61/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5658 - acc: 0.7172\n",
      "Epoch 62/100\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.5359 - acc: 0.7396\n",
      "Epoch 63/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5581 - acc: 0.7340\n",
      "Epoch 64/100\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.5457 - acc: 0.7217\n",
      "Epoch 65/100\n",
      "891/891 [==============================] - 0s 50us/step - loss: 0.5377 - acc: 0.7430\n",
      "Epoch 66/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5296 - acc: 0.7351\n",
      "Epoch 67/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5372 - acc: 0.7497\n",
      "Epoch 68/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5393 - acc: 0.7531\n",
      "Epoch 69/100\n",
      "891/891 [==============================] - 0s 51us/step - loss: 0.5469 - acc: 0.7363\n",
      "Epoch 70/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5375 - acc: 0.7284\n",
      "Epoch 71/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5346 - acc: 0.7250\n",
      "Epoch 72/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5528 - acc: 0.7318\n",
      "Epoch 73/100\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5178 - acc: 0.7430\n",
      "Epoch 74/100\n",
      "891/891 [==============================] - 0s 50us/step - loss: 0.5421 - acc: 0.7407\n",
      "Epoch 75/100\n",
      "891/891 [==============================] - 0s 57us/step - loss: 0.5440 - acc: 0.7374\n",
      "Epoch 76/100\n",
      "891/891 [==============================] - 0s 54us/step - loss: 0.5320 - acc: 0.7430\n",
      "Epoch 77/100\n",
      "891/891 [==============================] - 0s 40us/step - loss: 0.5530 - acc: 0.7284\n",
      "Epoch 78/100\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.5471 - acc: 0.7340\n",
      "Epoch 79/100\n",
      "891/891 [==============================] - 0s 39us/step - loss: 0.5198 - acc: 0.7565\n",
      "Epoch 80/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5276 - acc: 0.7565\n",
      "Epoch 81/100\n",
      "891/891 [==============================] - 0s 44us/step - loss: 0.5423 - acc: 0.7329\n",
      "Epoch 82/100\n",
      "891/891 [==============================] - 0s 44us/step - loss: 0.5245 - acc: 0.7396\n",
      "Epoch 83/100\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5415 - acc: 0.7329\n",
      "Epoch 84/100\n",
      "891/891 [==============================] - 0s 43us/step - loss: 0.5238 - acc: 0.7419\n",
      "Epoch 85/100\n",
      "891/891 [==============================] - 0s 41us/step - loss: 0.5339 - acc: 0.7452\n",
      "Epoch 86/100\n",
      "891/891 [==============================] - 0s 37us/step - loss: 0.5557 - acc: 0.7520\n",
      "Epoch 87/100\n",
      "891/891 [==============================] - 0s 37us/step - loss: 0.5240 - acc: 0.7430\n",
      "Epoch 88/100\n",
      "891/891 [==============================] - 0s 42us/step - loss: 0.5447 - acc: 0.7441\n",
      "Epoch 89/100\n",
      "891/891 [==============================] - 0s 40us/step - loss: 0.5215 - acc: 0.7464\n",
      "Epoch 90/100\n",
      "891/891 [==============================] - 0s 43us/step - loss: 0.5331 - acc: 0.7508\n",
      "Epoch 91/100\n",
      "891/891 [==============================] - 0s 35us/step - loss: 0.5288 - acc: 0.7486\n",
      "Epoch 92/100\n",
      "891/891 [==============================] - 0s 41us/step - loss: 0.5477 - acc: 0.7385\n",
      "Epoch 93/100\n",
      "891/891 [==============================] - 0s 41us/step - loss: 0.5280 - acc: 0.7553\n",
      "Epoch 94/100\n",
      "891/891 [==============================] - 0s 44us/step - loss: 0.5330 - acc: 0.7464\n",
      "Epoch 95/100\n",
      "891/891 [==============================] - 0s 43us/step - loss: 0.5153 - acc: 0.7666\n",
      "Epoch 96/100\n",
      "891/891 [==============================] - 0s 44us/step - loss: 0.5185 - acc: 0.7733\n",
      "Epoch 97/100\n",
      "891/891 [==============================] - 0s 43us/step - loss: 0.5221 - acc: 0.7508\n",
      "Epoch 98/100\n",
      "891/891 [==============================] - 0s 35us/step - loss: 0.5349 - acc: 0.7497\n",
      "Epoch 99/100\n",
      "891/891 [==============================] - 0s 39us/step - loss: 0.5222 - acc: 0.7374\n",
      "Epoch 100/100\n",
      "891/891 [==============================] - 0s 43us/step - loss: 0.5141 - acc: 0.7643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d7a5b95f28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Using Models\n",
    "- Save\n",
    "- Reload\n",
    "- Make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ramreddymyla\\\\Google Drive\\\\01 DS ML DL NLP and AI With Python Lab Copy\\\\03 Jupyter Notebooks\\\\Level 05_of_06_Deep_Learning_or_Neural_Network'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('model_file.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model('model_file.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions on new data / test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions: predictions\n",
    "y_test_pred = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90223515, 0.09776489],\n",
       "       [0.26734272, 0.7326573 ],\n",
       "       [0.635057  , 0.36494303],\n",
       "       [0.32956555, 0.67043453],\n",
       "       [0.8952818 , 0.10471816]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = y_test_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09776489 0.7326573  0.36494303 0.67043453 0.10471816 0.2403706\n",
      " 0.44842222 0.30744776 0.43521637 0.6613551  0.5458902  0.5864816\n",
      " 0.14793038 0.16991432 0.40288174 0.43626675 0.31354618 0.24142921\n",
      " 0.38722768 0.4406839  0.31326818 0.22988501 0.57016647 0.46584192\n",
      " 0.36293206 0.33910435 0.16938348 0.76062644 0.532098   0.11436121\n",
      " 0.39034858 0.7204378  0.5280745  0.06531911 0.5885541  0.45979443\n",
      " 0.16945736 0.14743426 0.4217985  0.5249475  0.23419112 0.51961476\n",
      " 0.1815116  0.6913231  0.5756046  0.11632831 0.27900824 0.5280745\n",
      " 0.2342581 ]\n"
     ]
    }
   ],
   "source": [
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted_prob_true\n",
    "predicted_prob_true.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please practice one example using iris dataset for Multi classes\n",
    "[refer iris dataset example](https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
